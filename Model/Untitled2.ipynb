{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import PyPDF2\n",
    "import os\n",
    "import collections\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import collections\n",
    "from gensim.models import Word2Vec\n",
    "import collections\n",
    "\n",
    "\n",
    "model = joblib.load('final.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfextract(file):\n",
    "    pdf_file = open(file, 'rb')\n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    number_of_pages = read_pdf.getNumPages()\n",
    "    c = collections.Counter(range(number_of_pages))\n",
    "    for i in c:\n",
    "        #page\n",
    "        page = read_pdf.getPage(i)\n",
    "        page_content = page.extractText()\n",
    "    return (page_content.encode('utf-8'))\n",
    "\n",
    "\n",
    "\n",
    "def create_profile(file):\n",
    "    model=Word2Vec.load(\"final.model\")\n",
    "    text = str(pdfextract(file))\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "\n",
    "    stats = [nlp(text[0]) for text in model.wv.most_similar(\"statistics\")]\n",
    "    NLP = [nlp(text[0]) for text in model.wv.most_similar(\"language\")]\n",
    "    ML = [nlp(text[0]) for text in model.wv.most_similar(\"machine_learning\")]\n",
    "    DL = [nlp(text[0]) for text in model.wv.most_similar(\"deep\")]\n",
    "    python = [nlp(text[0]) for text in model.wv.most_similar(\"python\")]\n",
    "    Data_Engineering = [nlp(text[0]) for text in model.wv.most_similar(\"data\")]\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Stats', None, *stats)\n",
    "    matcher.add('NLP', None, *NLP)\n",
    "    matcher.add('ML', None, *ML)\n",
    "    matcher.add('DL', None, *DL)\n",
    "    matcher.add('Python', None, *python)\n",
    "    matcher.add('DE', None, *Data_Engineering)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []  \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]  # get the unicode I\n",
    "        span = doc[start : end]               # get the matched slice of the doc\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    \n",
    "    ## convertimg string of keywords to dataframe\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    \n",
    "    base = os.path.basename(file)\n",
    "    filename = os.path.splitext(base)[0]\n",
    "    \n",
    "       \n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "    return(dataf)\n",
    "\n",
    "\n",
    "\n",
    "def scoreFile():\n",
    "    file = r'/home/abuba8/Desktop/Resume-Scoring-using-NLP-master/Resumes/AmanSharma.pdf'\n",
    "    final_db = pd.DataFrame()\n",
    "    dat = create_profile(file)\n",
    "    final_db = final_db.append(dat)\n",
    "    final_db2 = final_db['Keyword'].groupby([final_db['Candidate Name'], final_db['Subject']]).count().unstack()\n",
    "    final_db2.reset_index(inplace = True)\n",
    "    final_db2.fillna(0, inplace=True)\n",
    "    candidate_data = final_db2.iloc[:,1:]\n",
    "    candidate_data.index = final_db2['Candidate Name']\n",
    "    candidate_data['Total'] = candidate_data['DE']+candidate_data['DL']+candidate_data['ML']+candidate_data['NLP']+candidate_data['Python']+candidate_data['Stats']\n",
    "    candidate_data['Total'].sort_values(ascending=False)\n",
    "    return candidate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Subject</th>\n",
       "      <th>DE</th>\n",
       "      <th>DL</th>\n",
       "      <th>ML</th>\n",
       "      <th>NLP</th>\n",
       "      <th>Python</th>\n",
       "      <th>Stats</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Candidate Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amansharma</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Subject         DE  DL  ML  NLP  Python  Stats  Total\n",
       "Candidate Name                                       \n",
       "amansharma       3   3   4    5       4      4     23"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreFile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
